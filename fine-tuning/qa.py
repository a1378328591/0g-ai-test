from transformers import AutoTokenizer, AutoModelForQuestionAnswering
import torch

# åŠ è½½æ¨¡å‹å’Œ tokenizer
model_path = "qa_model"  # æ›¿æ¢ä¸ºä½ çš„å¾®è°ƒæ¨¡å‹ç›®å½•
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForQuestionAnswering.from_pretrained(model_path)

def answer_question(question, context):
    inputs = tokenizer(question, context, return_tensors="pt", truncation=True, padding=True, return_offsets_mapping=True)

    # åˆ é™¤ offset_mappingï¼Œé¿å…æŠ¥é”™
    if "offset_mapping" in inputs:
        del inputs["offset_mapping"]

    outputs = model(**inputs)
    start_logits = outputs.start_logits
    end_logits = outputs.end_logits

    start_index = torch.argmax(start_logits, dim=1).item()
    end_index = torch.argmax(end_logits, dim=1).item()

    if start_index > end_index or end_index - start_index > 30:
        return "(æ¨¡å‹æœªèƒ½æ‰¾åˆ°åˆé€‚ç­”æ¡ˆ)"

    answer_ids = inputs["input_ids"][0][start_index:end_index + 1]
    answer = tokenizer.decode(answer_ids, skip_special_tokens=True)
    return answer.strip()


if __name__ == "__main__":
    print("ğŸ“˜ è¾“å…¥ contextï¼ˆä¸Šä¸‹æ–‡ï¼‰ï¼Œç„¶åè¿ç»­æé—®ã€‚è¾“å…¥ :new æ¢ä¸Šä¸‹æ–‡ï¼Œè¾“å…¥ :exit æˆ– Ctrl+C é€€å‡ºã€‚\n")

    try:
        while True:
            context = input("ğŸ§¾ è¯·è¾“å…¥ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰ï¼š\n> ").strip()
            if not context:
                print("âš ï¸ ä¸Šä¸‹æ–‡ä¸èƒ½ä¸ºç©º")
                continue

            print("âœ… ä½ ç°åœ¨å¯ä»¥è¿ç»­æé—®äº†ï¼ˆè¾“å…¥ :new æ›´æ¢ä¸Šä¸‹æ–‡ï¼Œè¾“å…¥ :exit é€€å‡ºï¼‰")
            while True:
                question = input("\nâ“è¯·è¾“å…¥é—®é¢˜ï¼ˆquestionï¼‰ï¼š\n> ").strip()

                if question.lower() == ":new":
                    print("ğŸ”„ æ­£åœ¨åˆ‡æ¢ä¸Šä¸‹æ–‡...\n")
                    break
                elif question.lower() == ":exit":
                    print("ğŸ‘‹ å·²é€€å‡ºç¨‹åº")
                    exit(0)
                elif not question:
                    print("âš ï¸ é—®é¢˜ä¸èƒ½ä¸ºç©º")
                    continue

                answer = answer_question(question, context)
                print(f"ğŸ’¡ ç­”æ¡ˆ: {answer}")

    except KeyboardInterrupt:
        print("\nğŸ‘‹ å·²é€€å‡ºç¨‹åº")
